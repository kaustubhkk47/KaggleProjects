{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC, NuSVC, LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('Data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train.iloc[:,1:]\n",
    "train_Y = train.iloc[:,0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('Data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maddy\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:306: UserWarning: Trying to unpickle estimator StandardScaler from version 0.21.3 when using version 0.21.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "std_scaler_pickle = 'SaveFiles/std_scaler_pickle.pkl'\n",
    "with open(std_scaler_pickle, 'rb') as file:\n",
    "    std_scaler = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_scaled = std_scaler.transform(train_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Available SVMs  \n",
    "- SVC\n",
    "- NuSVC\n",
    "- LinearSVC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m\n",
       "\u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rbf'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdegree\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto_deprecated'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcoef0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mshrinking\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mprobability\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcache_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdecision_function_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ovr'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "C-Support Vector Classification.\n",
       "\n",
       "The implementation is based on libsvm. The fit time scales at least\n",
       "quadratically with the number of samples and may be impractical\n",
       "beyond tens of thousands of samples. For large datasets\n",
       "consider using :class:`sklearn.linear_model.LinearSVC` or\n",
       ":class:`sklearn.linear_model.SGDClassifier` instead, possibly after a\n",
       ":class:`sklearn.kernel_approximation.Nystroem` transformer.\n",
       "\n",
       "The multiclass support is handled according to a one-vs-one scheme.\n",
       "\n",
       "For details on the precise mathematical formulation of the provided\n",
       "kernel functions and how `gamma`, `coef0` and `degree` affect each\n",
       "other, see the corresponding section in the narrative documentation:\n",
       ":ref:`svm_kernels`.\n",
       "\n",
       "Read more in the :ref:`User Guide <svm_classification>`.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "C : float, optional (default=1.0)\n",
       "    Penalty parameter C of the error term.\n",
       "\n",
       "kernel : string, optional (default='rbf')\n",
       "    Specifies the kernel type to be used in the algorithm.\n",
       "    It must be one of 'linear', 'poly', 'rbf', 'sigmoid', 'precomputed' or\n",
       "    a callable.\n",
       "    If none is given, 'rbf' will be used. If a callable is given it is\n",
       "    used to pre-compute the kernel matrix from data matrices; that matrix\n",
       "    should be an array of shape ``(n_samples, n_samples)``.\n",
       "\n",
       "degree : int, optional (default=3)\n",
       "    Degree of the polynomial kernel function ('poly').\n",
       "    Ignored by all other kernels.\n",
       "\n",
       "gamma : float, optional (default='auto')\n",
       "    Kernel coefficient for 'rbf', 'poly' and 'sigmoid'.\n",
       "\n",
       "    Current default is 'auto' which uses 1 / n_features,\n",
       "    if ``gamma='scale'`` is passed then it uses 1 / (n_features * X.var())\n",
       "    as value of gamma. The current default of gamma, 'auto', will change\n",
       "    to 'scale' in version 0.22. 'auto_deprecated', a deprecated version of\n",
       "    'auto' is used as a default indicating that no explicit value of gamma\n",
       "    was passed.\n",
       "\n",
       "coef0 : float, optional (default=0.0)\n",
       "    Independent term in kernel function.\n",
       "    It is only significant in 'poly' and 'sigmoid'.\n",
       "\n",
       "shrinking : boolean, optional (default=True)\n",
       "    Whether to use the shrinking heuristic.\n",
       "\n",
       "probability : boolean, optional (default=False)\n",
       "    Whether to enable probability estimates. This must be enabled prior\n",
       "    to calling `fit`, and will slow down that method.\n",
       "\n",
       "tol : float, optional (default=1e-3)\n",
       "    Tolerance for stopping criterion.\n",
       "\n",
       "cache_size : float, optional\n",
       "    Specify the size of the kernel cache (in MB).\n",
       "\n",
       "class_weight : {dict, 'balanced'}, optional\n",
       "    Set the parameter C of class i to class_weight[i]*C for\n",
       "    SVC. If not given, all classes are supposed to have\n",
       "    weight one.\n",
       "    The \"balanced\" mode uses the values of y to automatically adjust\n",
       "    weights inversely proportional to class frequencies in the input data\n",
       "    as ``n_samples / (n_classes * np.bincount(y))``\n",
       "\n",
       "verbose : bool, default: False\n",
       "    Enable verbose output. Note that this setting takes advantage of a\n",
       "    per-process runtime setting in libsvm that, if enabled, may not work\n",
       "    properly in a multithreaded context.\n",
       "\n",
       "max_iter : int, optional (default=-1)\n",
       "    Hard limit on iterations within solver, or -1 for no limit.\n",
       "\n",
       "decision_function_shape : 'ovo', 'ovr', default='ovr'\n",
       "    Whether to return a one-vs-rest ('ovr') decision function of shape\n",
       "    (n_samples, n_classes) as all other classifiers, or the original\n",
       "    one-vs-one ('ovo') decision function of libsvm which has shape\n",
       "    (n_samples, n_classes * (n_classes - 1) / 2). However, one-vs-one\n",
       "    ('ovo') is always used as multi-class strategy.\n",
       "\n",
       "    .. versionchanged:: 0.19\n",
       "        decision_function_shape is 'ovr' by default.\n",
       "\n",
       "    .. versionadded:: 0.17\n",
       "       *decision_function_shape='ovr'* is recommended.\n",
       "\n",
       "    .. versionchanged:: 0.17\n",
       "       Deprecated *decision_function_shape='ovo' and None*.\n",
       "\n",
       "random_state : int, RandomState instance or None, optional (default=None)\n",
       "    The seed of the pseudo random number generator used when shuffling\n",
       "    the data for probability estimates. If int, random_state is the\n",
       "    seed used by the random number generator; If RandomState instance,\n",
       "    random_state is the random number generator; If None, the random\n",
       "    number generator is the RandomState instance used by `np.random`.\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "support_ : array-like, shape = [n_SV]\n",
       "    Indices of support vectors.\n",
       "\n",
       "support_vectors_ : array-like, shape = [n_SV, n_features]\n",
       "    Support vectors.\n",
       "\n",
       "n_support_ : array-like, dtype=int32, shape = [n_class]\n",
       "    Number of support vectors for each class.\n",
       "\n",
       "dual_coef_ : array, shape = [n_class-1, n_SV]\n",
       "    Coefficients of the support vector in the decision function.\n",
       "    For multiclass, coefficient for all 1-vs-1 classifiers.\n",
       "    The layout of the coefficients in the multiclass case is somewhat\n",
       "    non-trivial. See the section about multi-class classification in the\n",
       "    SVM section of the User Guide for details.\n",
       "\n",
       "coef_ : array, shape = [n_class * (n_class-1) / 2, n_features]\n",
       "    Weights assigned to the features (coefficients in the primal\n",
       "    problem). This is only available in the case of a linear kernel.\n",
       "\n",
       "    `coef_` is a readonly property derived from `dual_coef_` and\n",
       "    `support_vectors_`.\n",
       "\n",
       "intercept_ : array, shape = [n_class * (n_class-1) / 2]\n",
       "    Constants in decision function.\n",
       "\n",
       "fit_status_ : int\n",
       "    0 if correctly fitted, 1 otherwise (will raise warning)\n",
       "\n",
       "probA_ : array, shape = [n_class * (n_class-1) / 2]\n",
       "probB_ : array, shape = [n_class * (n_class-1) / 2]\n",
       "    If probability=True, the parameters learned in Platt scaling to\n",
       "    produce probability estimates from decision values. If\n",
       "    probability=False, an empty array. Platt scaling uses the logistic\n",
       "    function\n",
       "    ``1 / (1 + exp(decision_value * probA_ + probB_))``\n",
       "    where ``probA_`` and ``probB_`` are learned from the dataset [2]_. For\n",
       "    more information on the multiclass case and training procedure see\n",
       "    section 8 of [1]_.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> import numpy as np\n",
       ">>> X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])\n",
       ">>> y = np.array([1, 1, 2, 2])\n",
       ">>> from sklearn.svm import SVC\n",
       ">>> clf = SVC(gamma='auto')\n",
       ">>> clf.fit(X, y) #doctest: +NORMALIZE_WHITESPACE\n",
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)\n",
       ">>> print(clf.predict([[-0.8, -1]]))\n",
       "[1]\n",
       "\n",
       "See also\n",
       "--------\n",
       "SVR\n",
       "    Support Vector Machine for Regression implemented using libsvm.\n",
       "\n",
       "LinearSVC\n",
       "    Scalable Linear Support Vector Machine for classification\n",
       "    implemented using liblinear. Check the See also section of\n",
       "    LinearSVC for more comparison element.\n",
       "\n",
       "References\n",
       "----------\n",
       ".. [1] `LIBSVM: A Library for Support Vector Machines\n",
       "    <http://www.csie.ntu.edu.tw/~cjlin/papers/libsvm.pdf>`_\n",
       "\n",
       ".. [2] `Platt, John (1999). \"Probabilistic outputs for support vector\n",
       "    machines and comparison to regularizedlikelihood methods.\"\n",
       "    <http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.41.1639>`_\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\users\\kaustubh\\anaconda3\\lib\\site-packages\\sklearn\\svm\\classes.py\n",
       "\u001b[1;31mType:\u001b[0m           ABCMeta\n",
       "\u001b[1;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_range = np.logspace(-2, 10, 13)\n",
    "gamma_range = np.logspace(-9, 3, 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_svc = SVC(kernel ='linear', tol = 1e-4, class_weight ='balanced', random_state = random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_svc_grid_params = {'C' : C_range}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_svc_grid_search = GridSearchCV(estimator=linear_svc,\n",
    "                                      param_grid=linear_svc_grid_params,\n",
    "                                      scoring='accuracy',\n",
    "                                      cv=cv,\n",
    "                                      n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_svc_grid_search.fit(train_X_scaled, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_svc_pickle = 'SaveFiles/linear_svc_pickle.pkl'\n",
    "with open(linear_svc_pickle, 'wb') as file:\n",
    "    pickle.dump(linear_svc_grid_search, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gamma  \n",
    " - high value indicates steeper drop in influence, ie possibility of overfitting\n",
    " - low value indicates slower drop in influence, ie possibility of underfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_svc = SVC(kernel ='rbf', tol = 1e-4, class_weight ='balanced', random_state = random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_svc_grid_params = {'C' : C_range, 'gamma' : gamma_range}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_svc_grid_search = GridSearchCV(estimator=rbf_svc,\n",
    "                                      param_grid=rbf_svc_grid_params,\n",
    "                                      scoring='accuracy',\n",
    "                                      cv=cv,\n",
    "                                      n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_svc_grid_search.fit(train_X_scaled, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_svc_pickle = 'SaveFiles/rbf_svc_pickle.pkl'\n",
    "with open(rbf_svc_pickle, 'wb') as file:\n",
    "    pickle.dump(rbf_svc_grid_search, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc-showcode": false,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
